---
title: "Datacenter Myths"
author: Andreas
author_image: andreas.jpg
tags: sustainability, tech
published_at: 2017-10-12
post_image: myth_big_datacenters_are_efficient.jpg
---

## Hyperscale realities are very different to what most people think

### Myth 1: Bigger data centers are more efficient

There are advantages in building larger scale data centers, like economies of scale and shear bulk buying power, but these are not as significant as what people think. The average cost per rack in a hyper scale data center is $20-35K USD including all energy requirements and safety systems. The cost of hardware per rack is around the $200-300K USD mark.

What is often forgotten is that anything that is of enormous scale and highly concentrated comes with complexity and specific problems to deal with. For example. resource requirements such as investment, operational costs, knowledge and people increase significantly with size.

In reality keeping things simple, small and distributed is much more cost effective than a big complex environment.

### Myth 2: Big data centers can be sustainable

The carbon footprint of a big datacenter is enormous. To improve the power usage effectiveness (PUE) of most data center farmers have adopted wind, hydro and/or solar power technologies, which indeed helps drop their PUE by an estimated 20%. But is this really leading to more sustainability?

This 20% looks great on paper and in the farmers' corporate social responsibility reports. However, it just represents an improvement on the cooling technology and sourcing of energy. It doesn't actually impact the energy consumed by the equipment that runs in their data centers (servers, storage chassis, physical disks, etc) and this equipment is responsible for the carbon footprint. PUE only refers to overhead power consumption, i.e. cooling the facility, opening and closing doors, maintaining power security systems, etc.

So real improvement lies in deploying technologies that actually consume less power to deliver the actual Internet capacity to run workloads, real CPU chassis, physical disks and storage cabinets. Improving on how hardware is being more effectively used can have an impact of up-to 1000% and lead to 10 times more power efficiency.

### Myth 3: Redundant systems have better uptime

A lot of us believe that systems need redundancy mechanisms to improve their operational uptime and reliability. While it may make sense to IT experts, let's translate this for the non-IT world?

To make a car more reliable we add redundancy (as we do in IT). So for the risk of having a puncture we add one extra tire for all the tires we use continuously. This adds 4 extra tires to the car. Then a decision needs to be made: Do we put those tires in a structure where they are always running along the primary tires or do we choose not to have them "on line" all the time, wearing and tearing in the same way as the primary tires?

Building such a system would take a large number of engineers to come up with a solution, and would change cars as we know them. Wouldn't it make more sense to think outside the box and solve the root of the problem by making tires un-deflatable?

The IT industry has gone overboard  with the concept of redundancy, having forgotten to look at the root cause issues. This has spawned a whole new industry of itself, which has a financial interest in creating complicated and expensive redundant system.

### Myth 4: Big companies optimize better

Big companies with a certain track record will know better how to optimize as they have more people and resources.

At first glance this sounds logical, but if we look at the IT landscape today 90%+ of the innovation within the IT space is done by small startups. The giant IT companies have a heritage they hardly can overcome. They are locked in old infrastructure designs, and building outside of that infrastructure would be costly, timely and probably put the breaks on their businesses.

Real innovation gives way to fix the core symptoms rather than taking the problem pain-killer approach.
